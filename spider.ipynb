{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_examples(X: np.ndarray, Y: np.ndarray, k: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Classify examples as noisy or safe based on their k nearest neigbors.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): The feature matrix of shape (n_samples, n_features).\n",
    "        Y (numpy.ndarray): The target labels of shape(n_samples,).\n",
    "        k (int, optional): The number of nearest neighbors to consider, defaults to 3.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: An array of flags indicating the type of each example (0 for safe, 1 for noisy).\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    flags = np.zeros(n_samples, dtype=int)  # Intialize flags for all examples as safe\n",
    "\n",
    "    # Fit a k-nearest neighbors model\n",
    "    nn = NearestNeighbors(n_neighbors=k)\n",
    "    nn.fit(X)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        example = X[i]\n",
    "        label = Y[i]\n",
    "\n",
    "        # Find the indices of the k nearest neigbors\n",
    "        indices = nn.kneighbors([example], return_distance=False)\n",
    "\n",
    "        # Exclude the current example itself from the neigbors\n",
    "        neighbors_indices = indices[0][1:]\n",
    "\n",
    "        # Check if the majority of neighbors have the same label as the current example\n",
    "        if np.sum(Y[neighbors_indices] == label) >= k // 2:\n",
    "            flags[i] = 0    # Set flag as safe\n",
    "        else:\n",
    "            flags[i] = 1    # Set flag as noisy\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_knn_indices(k, majority_class, example, safe_noisy_class, flags, Y, X):\n",
    "    \"\"\"\n",
    "    Find the indices of the safe examples among its k nearest neigbors.\n",
    "\n",
    "    Args:\n",
    "        k (int): The number of nearest neigbors to consider.\n",
    "        majority_class (int): The label of the majority class.\n",
    "        example (np.ndarray): The example for which to find the nearest neigbors.\n",
    "        safe_noisy_class (int): The class type (0 for safe, 1 for noisy) to consider.\n",
    "        flags (np.ndarray): The flags indicating the type of each example (0 for safe, 1 for noisy).\n",
    "        Y (np.ndarray): The target labels of shape (n_samples,)\n",
    "        X (np.ndarray): The feature matrix of shape (n_samples, n_features).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The indices of the safe examples among its k nearest neigbors.\n",
    "    \"\"\"\n",
    "    # Find the indices of the safe examples among its k nearest neigbors\n",
    "    safe_indices = np.where((flags == safe_noisy_class) & (Y == majority_class))[0]\n",
    "\n",
    "    # Calculate distances between the example and safe examples\n",
    "    distances = []\n",
    "    for safe_ind in safe_indices:\n",
    "        distances.append(np.linalg.norm(X[safe_ind] - example))\n",
    "\n",
    "    # Combine distances and indices\n",
    "    combined = zip(distances, safe_indices)\n",
    "\n",
    "    # Sort the combined list based on distances\n",
    "    sorted_combined = sorted(combined)\n",
    "    sorted_distances, sorted_indices = zip(*sorted_combined)\n",
    "\n",
    "    # Get the indices of the k nearest neigbors\n",
    "    knn_indices = sorted_indices[:k]\n",
    "    return knn_indices[:k]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_amplification(X: np.ndarray, Y: np.ndarray, flags: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Performs weak amplification by creating copies of noisy examples.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): The feature matrix of shape (n_samples, n_features).\n",
    "        Y (numpy.ndarray): The target labels of shape (n_samples,).\n",
    "        flags (numpy.ndarray): The flags indicating the type of each example (0 for safe, 1 for noisy).\n",
    "\n",
    "    Returns:\n",
    "        tuple[numpy.ndarray, numpy.ndarray]: The updated feature matrix after ampflication and \n",
    "                                             the updated target labels after amplification.\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]  # Get the number of samples in the feature matrix X\n",
    "    new_X = X.copy()    # Create copy of the feature matrix X to store the updated values\n",
    "    new_Y = Y.copy()    # Create copy of the target labels Y to store the updated values\n",
    "    flags_new = flags.copy()\n",
    "    k = 3   # Set the value of k to determine the number of nearest neigbors to consider\n",
    "\n",
    "    # Determine the majority class label based on the target labels\n",
    "    majority_class_label = np.argmax(np.bincount(Y))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        if flags[i] == 1:   # Check it the sample is flagged as noisy\n",
    "            example = X[i]  # Get the example for the current sample\n",
    "            label = Y[i]    # Get the label for the current sample\n",
    "\n",
    "            # Find the indexes of safe majority class examples among the k nearest neighbors\n",
    "            safe_indices = find_knn_indices(k, majority_class_label, example, 0, flags, Y, X)\n",
    "            \n",
    "            # Amplify the example by creating copies\n",
    "            for idx in safe_indices:\n",
    "                new_X = np.vstack((new_X, example))\n",
    "                new_Y = np.hstack((new_Y, label))\n",
    "                flags_new = np.hstack((flags_new, 1))\n",
    "    return new_X, new_Y, flags_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags [0 0 0 0 1]\n",
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]\n",
      " [ 9 10]\n",
      " [ 9 10]]\n",
      "[0 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([0, 0, 1, 1, 0])\n",
    "flags = classify_examples(X, y)\n",
    "print(\"flags\", flags)\n",
    "\n",
    "new_X, new_y, _ = weak_amplification(X, y, flags)\n",
    "print(new_X)\n",
    "print(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_amplification_and_relabeling(X: np.ndarray, y: np.ndarray, flags: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform weak amplification and relabeling by creating copies of noisy examples and relabeling their nearest noisy neighbors.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The feature matrix of shape (n_samples, n_features).\n",
    "        y (np.ndarray): The target labels of shape (n_samples,).\n",
    "        flags (np.ndarray): The flags indicating the type of each example (0 for safe, 1 for noisy).\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]: The updated feature matrix after amplification and relabeling, and the updated target labels after amplification and relabeling.\n",
    "    \"\"\"\n",
    "    # Get the number of samples in the feature matrix X\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Create copies of the feature matrix X and the target labels y to store the updated values\n",
    "    new_X = X.copy()\n",
    "    new_y = y.copy()\n",
    "    flags_new = flags.copy()\n",
    "\n",
    "    # Find the majority class label by counting the occurrences of each class label in y and selecting the label with the highest count\n",
    "    majority_class_label = np.argmax(np.bincount(y))\n",
    "\n",
    "    # Get the unique class labels present in the target labels y\n",
    "    unique_labels = np.unique(y)\n",
    "\n",
    "    # Find the minority class label by identifying the label that is not the majority class label\n",
    "    minority_class_label = np.setdiff1d(unique_labels, majority_class_label)[0]\n",
    "\n",
    "    # Set the value of k for the number of nearest neighbors to consider\n",
    "    k = 3\n",
    "\n",
    "    # Iterate over each sample in the dataset\n",
    "    for i in range(n_samples):\n",
    "        # If the sample is flagged as noisy (flags[i] == 1)\n",
    "        if flags[i] == 1:\n",
    "            # Get the example and label for the current sample\n",
    "            example = X[i]\n",
    "            label = y[i]\n",
    "\n",
    "            # Find the indices of the safe examples among its k nearest neighbors by calling the find_knn_indices function\n",
    "            safe_indices = find_knn_indices(k, majority_class_label, example, 0, flags, y, X)\n",
    "\n",
    "            # Amplify the example by creating copies of it and appending them to new_X and new_y\n",
    "            for idx in safe_indices:\n",
    "                new_X = np.vstack((new_X, example))\n",
    "                new_y = np.hstack((new_y, label))\n",
    "                flags_new = np.hstack((flags_new, 1)) # flags_new moze miec inna definicje niz flags\n",
    "\n",
    "            # Relabel the noisy neighbors in the majority class to the minority class by updating their labels in new_y\n",
    "            noisy_indices = find_knn_indices(k, majority_class_label, example, 1, flags, y, X)\n",
    "            for idx in noisy_indices:\n",
    "                new_y[idx] = minority_class_label\n",
    "\n",
    "    # Return the updated feature matrix new_X and the updated target labels new_y\n",
    "    return new_X, new_y, flags_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags [0 0 0 0 1 1 0]\n",
      "Weak Amplification and Relabeling:\n",
      "Original X:\n",
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]\n",
      " [13 14]]\n",
      "Original y:\n",
      "[0 0 1 1 0 1 0]\n",
      "New X after weak amplification and relabeling:\n",
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]\n",
      " [13 14]\n",
      " [ 9 10]\n",
      " [ 9 10]\n",
      " [ 9 10]\n",
      " [11 12]\n",
      " [11 12]\n",
      " [11 12]]\n",
      "New y after weak amplification and relabeling:\n",
      "[0 0 1 1 1 1 0 0 0 0 1 1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14]])\n",
    "y = np.array([0, 0, 1, 1, 0, 1, 0])\n",
    "flags = classify_examples(X, y)\n",
    "print(\"flags\", flags)\n",
    "\n",
    "# Weak Amplification and Relabeling\n",
    "new_X_weak_relabel, new_y_weak_relabel, _ = weak_amplification_and_relabeling(X, y, flags)\n",
    "print(\"Weak Amplification and Relabeling:\")\n",
    "print(\"Original X:\")\n",
    "print(X)\n",
    "print(\"Original y:\")\n",
    "print(y)\n",
    "print(\"New X after weak amplification and relabeling:\")\n",
    "print(new_X_weak_relabel)\n",
    "print(\"New y after weak amplification and relabeling:\")\n",
    "print(new_y_weak_relabel)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strong_amplification(X: np.ndarray, y: np.ndarray, flags: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform strong amplification by creating copies of safe and noisy examples, and remove all noisy majority class examples.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The feature matrix of shape (n_samples, n_features).\n",
    "        y (np.ndarray): The target labels of shape (n_samples,).\n",
    "        flags (np.ndarray): The flags indicating the type of each example (0 for safe, 1 for noisy).\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]: The updated feature matrix after amplification, and the updated target labels after amplification.\n",
    "    \"\"\"\n",
    "    # Get the number of samples in the feature matrix X\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Create copies of the feature matrix X, target labels y, and flags to store the updated values\n",
    "    new_X = X.copy()\n",
    "    new_y = y.copy()\n",
    "    flags_new = flags.copy()\n",
    "\n",
    "    # Set the value of k for the number of nearest neighbors to consider as 3\n",
    "    k = 3\n",
    "\n",
    "    # Determine the majority class label by counting the occurrences of each class label in y and selecting the label with the highest count\n",
    "    majority_class_label = np.argmax(np.bincount(y))\n",
    "\n",
    "    # Get the unique class labels present in the target labels y\n",
    "    unique_labels = np.unique(y)\n",
    "\n",
    "    # Determine the minority class label by excluding the majority class label from the unique labels\n",
    "    minority_class_label = np.setdiff1d(unique_labels, majority_class_label)[0]\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # If the sample is flagged as safe (flags[i] == 0) and has the minority class label\n",
    "        if flags[i] == 0 and y[i] == minority_class_label:\n",
    "            # Get the example and label for the current sample\n",
    "            example = X[i]\n",
    "            label = y[i]\n",
    "\n",
    "            # Find the indices of the safe examples among its k nearest neighbors by calling the find_knn_indices function\n",
    "            knn_indices = find_knn_indices(k, majority_class_label, example, 0, flags, y, X)\n",
    "\n",
    "            # Amplify the example by creating copies and append them to new_X, new_y, and flags_new arrays\n",
    "            for idx in knn_indices:\n",
    "                new_X = np.vstack((new_X, example))\n",
    "                new_y = np.hstack((new_y, label))\n",
    "                flags_new = np.hstack((flags_new, 0))\n",
    "\n",
    "        # If the sample is flagged as noisy (flags[i] == 1) and has the minority class label\n",
    "        if flags[i] == 1 and y[i] == minority_class_label:\n",
    "            # Get the example and label for the current sample\n",
    "            example = X[i]\n",
    "            label = y[i]\n",
    "\n",
    "            # Classify the examples using k=5 to determine the flags for each example\n",
    "            flags_5 = classify_examples(X, y, 5)\n",
    "\n",
    "            # Check if the flag for the current sample is safe (flag_i == 0) and set k_s to 3, otherwise set k_s to 5\n",
    "            flag_i = flags_5[i]\n",
    "            if flag_i == 0:\n",
    "                k_s = 3\n",
    "            else:\n",
    "                k_s = 5\n",
    "\n",
    "            # Find the indices of the safe examples among its k_s nearest neighbors by calling the find_knn_indices function\n",
    "            knn_indices = find_knn_indices(k_s, majority_class_label, example, 0, flags, y, X)\n",
    "\n",
    "            # Amplify the example by creating copies and append them to new_X, new_y, and flags_new arrays\n",
    "            for idx in knn_indices:\n",
    "                new_X = np.vstack((new_X, example))\n",
    "                new_y = np.hstack((new_y, label))\n",
    "                flags_new = np.hstack((flags_new, 1))\n",
    "\n",
    "    # Return the updated feature matrix new_X and the updated target labels new_y\n",
    "    return new_X, new_y, flags_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags [0 0 0 0 1]\n",
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]\n",
      " [ 9 10]\n",
      " [ 9 10]]\n",
      "[0 0 1 1 0 0 0]\n",
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]\n",
      " [ 9 10]\n",
      " [ 9 10]]\n",
      "[0 0 1 1 1 0 0]\n",
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]\n",
      " [ 5  6]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 7  8]]\n",
      "[0 0 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([0, 0, 1, 1, 0])\n",
    "flags = classify_examples(X, y)\n",
    "print(\"flags\", flags)\n",
    "\n",
    "new_X, new_y, _ = weak_amplification(X, y, flags)\n",
    "print(new_X)\n",
    "print(new_y)\n",
    "\n",
    "new_X, new_y, _ = weak_amplification_and_relabeling(X, y, flags)\n",
    "print(new_X)\n",
    "print(new_y)\n",
    "\n",
    "new_X, new_y, _ = strong_amplification(X, y, flags)\n",
    "print(new_X)\n",
    "print(new_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
